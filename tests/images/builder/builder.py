import copy
import logging
import multiprocessing
import multiprocessing.dummy
import re
import shutil
import yaml
import threading
import tempfile

from contextlib import ExitStack
from cryptography.hazmat.backends import default_backend as crypto_default_backend
from cryptography.hazmat.primitives import serialization as crypto_serialization
from cryptography.hazmat.primitives.asymmetric import rsa, ed25519
from pathlib import Path
from typing import List, Optional, Tuple

from builder import ArtifactManifest, ImageConfig, OutputFormat, customize, sign
from builder.context_managers import temp_dir, temp_file

logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

# Name of helper configuration file generated by Image Customizer under the same directory as
# output artifacts, when output.artifacts feature is used. This file is used to inject signed
# artifacts back into an image. Docs:
# https://microsoft.github.io/azure-linux-image-tools/imagecustomizer/api/configuration/injectFilesConfig.html.
INJECT_FILES_YAML = "inject-files.yaml"


def build_image(
    *,
    container_image: str,
    image: ImageConfig,
    output_dir: Path,
    artifacts: ArtifactManifest,
    clones: int = 1,
    rpm_sources: List[Path] = [],
    dry_run: bool = False,
    force: bool = False,
):
    """Build the image using the specified Image Customizer container."""

    if not dry_run:
        # Create the output directory if it doesn't exist
        output_dir.mkdir(parents=True, exist_ok=True)
        log.info(f"Output directory: {output_dir}")

    ssh_file = generate_ssh_keys(
        output_dir,
        image,
        dry_run=dry_run,
    )

    # If image needs signing, generate a CA certificate
    ca_tmp_dir, ca_nss_key_db = None, None
    if image.get_output_artifacts_dir():
        ca_tmp_dir = Path(tempfile.mkdtemp(prefix="ca_"))
        ca_nss_key_db = sign.generate_ca_certificate(ca_tmp_dir)

    try:
        if clones == 1:
            build_one(
                container_image,
                image,
                output_dir,
                rpm_sources,
                dry_run,
                force,
                ca_nss_key_db=ca_nss_key_db,
            )
        else:
            # Parallel execution
            build_with_clones(
                container_image,
                image,
                output_dir,
                clones,
                rpm_sources,
                dry_run,
                force,
                ca_nss_key_db=ca_nss_key_db,
            )

        # Publish the CA certificate to the output dir
        if ca_nss_key_db and not dry_run:
            sign.publish_ca_certificate(ca_nss_key_db, output_dir)

    finally:
        if ssh_file:
            # Clean up the SSH key file
            ssh_file.unlink(missing_ok=True)
            log.info(f"SSH key file {ssh_file} removed.")

        # Clean up the CA temporary directory
        if ca_tmp_dir:
            shutil.rmtree(ca_tmp_dir, ignore_errors=True)
            log.info(f"CA temporary directory {ca_tmp_dir} removed.")


def build_one(
    container_image: str,
    image: ImageConfig,
    output_dir: Path,
    rpm_sources: List[Path] = [],
    dry_run: bool = False,
    force: bool = False,
    ca_nss_key_db: Optional[Path] = None,
):
    for dep in image.dependencies():
        if not dep.exists():
            raise FileNotFoundError(f"Dependency '{dep}' does not exist.")

    # Check if final image output exists, to see if building is necessary
    output_file = output_dir / image.file_name()
    if output_file.exists():
        log.info(f"Output file {output_file} already exists.")
        if force:
            log.info(f"Force build requested for '{image.id}', rebuilding.")
        else:
            dest_mod_time = output_file.stat().st_mtime
            for dep in image.dependencies():
                if dep.is_dir():
                    # Ignore directories
                    continue
                if dep.stat().st_mtime > dest_mod_time:
                    log.info(f"Dependency '{dep}' is newer than output file.")
                    break
            else:
                log.info(f"Output file {output_file} is up to date.")
                return output_file

    # Copy RPM sources to standalone temporary directories
    with ExitStack() as stack:
        tmp_rpm_sources = []
        for rpm_src in rpm_sources:
            # Create a temporary directory for each RPM source, delete with sudo because
            # createrepo is run as root.
            tmp = stack.enter_context(
                temp_dir(prefix=f"rpm-{rpm_src.stem}-", sudo=True)
            )
            tmp_rpm_sources.append(tmp)
            log.debug(f"Copying RPM source {rpm_src} to {tmp}")
            shutil.copytree(rpm_src, tmp, dirs_exist_ok=True)

        # If config YAML contains output.artifacts, then need to output signed image. First, build
        # an unsigned image; then, sign boot artifacts, and inject the signed copies back, to build
        # a signed image as final output.
        if image.get_output_artifacts_dir():
            build_signed_image(
                stack,
                container_image,
                image,
                tmp_rpm_sources,
                output_dir,
                output_file,
                ca_nss_key_db,
                dry_run,
            )
        else:
            # Otherwise, only build an unsigned image
            customize.build_config(
                container_image,
                image.id,
                image.full_yaml_path(),
                image.base_image.path,
                image.output_format.ic_name(),
                output_file,
                tmp_rpm_sources,
                dry_run,
            )

    output_file = output_dir / image.file_name()
    log.info(f"Image '{image.id}' built successfully in {output_file}")


def build_with_clones(
    container_image: str,
    image: ImageConfig,
    output_dir: Path,
    clones: int,
    rpm_sources: List[Path] = [],
    dry_run: bool = False,
    force: bool = False,
    ca_nss_key_db: Optional[Path] = None,
):
    # Build all the clones in parallel
    build_clones(
        container_image,
        image,
        output_dir,
        clones,
        rpm_sources,
        dry_run,
        force,
        ca_nss_key_db=ca_nss_key_db,
    )

    # In the future, when enabled by Prism, we want to build an intermediate
    # image and then build the clones from that image. Leaving that code here
    # for future reference.

    # # Extract kernel command line config
    # with open(yaml_path, "r") as f:
    #     config = yaml.load(f, Loader=yaml.Loader)
    # kernel_cmdline = (
    #     config.get("os", {}).get("kernelCommandLine", {}).get("extraCommandLine", [])
    # )

    # # Run the build process once for the intermediate image.
    # intermediate_img = build_one(
    #     build_runtime,
    #     f"{config_name}-intermediate",
    #     yaml_path,
    #     base_image,
    #     OutputFormat.RAW,
    #     output_dir,
    #     rpm_sources,
    #     dry_run,
    # )

    # log.info(f"Intermediate image created: {intermediate_img}")

    # cfg = tempfile.NamedTemporaryFile(mode="w", encoding="utf-8", suffix=".yaml")
    # try:
    #     final_yaml = yaml.dump(
    #         {
    #             "storage": {
    #                 "resetPartitionsUuidsType": "reset-all",
    #             },
    #             "os": {
    #                 "bootloader": {
    #                     "resetType": "hard-reset",
    #                 },
    #                 # Preserve the kernel command line from the original config
    #                 "kernelCommandLine": {
    #                     "extraCommandLine": kernel_cmdline,
    #                 },
    #             },
    #         },
    #         Dumper=yaml.Dumper,
    #     )
    #     log.debug(f"Final YAML:\n{final_yaml}")
    #     cfg.write(final_yaml)
    #     cfg.flush()
    #     cfg.seek(0)

    #     build_clones(
    #         build_runtime,
    #         config_name,
    #         Path(cfg.name),
    #         intermediate_img,
    #         img_format,
    #         output_dir,
    #         clones,
    #         rpm_sources,
    #         dry_run,
    #     )
    # finally:
    #     # Clean up the temporary files
    #     cfg.close()
    #     intermediate_img.unlink(missing_ok=True)


def build_clones(
    container_image: str,
    image: ImageConfig,
    output_dir: Path,
    clones: int,
    rpm_sources: List[Path] = [],
    dry_run: bool = False,
    force: bool = False,
    ca_nss_key_db: Optional[Path] = None,
):
    def clone_image(image: ImageConfig, clone_index: int) -> ImageConfig:
        img = copy.deepcopy(image)
        img.set_suffix(str(clone_index))
        return img

    pool = multiprocessing.dummy.Pool(clones)
    try:
        log.info(f"Building {clones} clones of {image.name}")
        results = pool.starmap(
            build_one,
            [
                (
                    container_image,
                    clone_image(image, i),
                    output_dir,
                    rpm_sources,
                    dry_run,
                    force,
                    ca_nss_key_db,
                )
                for i in range(clones)
            ],
        )
        return results
    finally:
        pool.close()
        pool.join()


def generate_ssh_keys(
    output_dir: Path,
    image: ImageConfig,
    dry_run: bool = False,
) -> Optional[Path]:
    """Generate SSH keys for the image."""
    if not image.ssh_key:
        return

    # the artifact path is relative to the image's YAML file
    artifact_path = image.full_yaml_path().parent / image.ssh_key

    if artifact_path.exists():
        log.warning(
            f"SSH key file {artifact_path} already exists, not generating a new key!"
        )
        return artifact_path

    filename = image.ssh_key.name
    m = re.match(r"^id_(rsa|ed25519).pub$", filename)
    if not m:
        raise ValueError(f"Invalid SSH key name: {filename}")

    key_type = m.group(1)

    if key_type == "rsa":
        key = rsa.generate_private_key(
            backend=crypto_default_backend(), public_exponent=65537, key_size=2048
        )
    elif key_type == "ed25519":
        key = ed25519.Ed25519PrivateKey.generate()
    else:
        raise ValueError(f"Unsupported SSH key type: {key_type}")

    private_key = key.private_bytes(
        crypto_serialization.Encoding.PEM,
        crypto_serialization.PrivateFormat.TraditionalOpenSSL,
        crypto_serialization.NoEncryption(),
    )

    public_key = key.public_key().public_bytes(
        crypto_serialization.Encoding.OpenSSH, crypto_serialization.PublicFormat.OpenSSH
    )

    if dry_run:
        print(f"Dry run: would generate SSH keys for {image.name}")
        print(f"Private key: {private_key.decode()}")
        print(f"Public key: {public_key.decode()}")
        return

    # Write the private key to a file
    private_key_path = output_dir / f"key_{image.name}_private.pem"
    public_key_path = output_dir / f"key_{image.name}_public.pub"
    with open(private_key_path, "wb") as f:
        f.write(private_key)
    with open(public_key_path, "wb") as f:
        f.write(public_key)

    with open(artifact_path, "wb") as f:
        f.write(public_key)
    log.info(f"SSH keys generated for {image.name}")

    return artifact_path


def build_signed_image(
    stack: ExitStack,
    container_image: str,
    image: ImageConfig,
    tmp_rpm_sources: List[Path],
    output_dir: Path,
    output_file: Path,
    ca_nss_key_db: Path,
    dry_run: bool = False,
):

    # Set up thread-specific YAML and output artifacts directory
    working_yaml_path, output_artifacts_dir = setup_temp_yaml_and_dir(stack, image)

    # Construct the path to the unsigned image
    unsigned_output_file = output_artifacts_dir / image.file_name_unsigned_raw()
    log.debug(
        f"Process with PID {threading.get_ident()} will write unsigned image and output artifacts to {output_artifacts_dir.absolute()}"
    )

    # Build the unsigned image
    customize.build_config(
        container_image,
        image.id,
        working_yaml_path,
        image.base_image.path,
        # Set output format of unsigned image to raw file since that's the format used
        # internally by Image Customizer for file injection
        OutputFormat.RAW.ic_name(),
        unsigned_output_file,
        tmp_rpm_sources,
        dry_run,
    )

    log.info(f"Building signed image: {output_file}")

    # Generate a leaf certificate for this clone using the CA certificate. The leaf certificate
    # must be generated in the same NSS key database as the CA certificate.
    leaf_key_name = sign.generate_leaf_certificate(ca_nss_key_db, image.id)

    # Construct full path of inject-files.yaml
    inject_files_yaml_path = output_artifacts_dir / INJECT_FILES_YAML
    # Sign boot artifacts that Image Customizer output when building the unsigned image
    sign.sign_boot_artifacts(
        ca_nss_key_db,
        leaf_key_name,
        image.get_items_to_sign(),
        inject_files_yaml_path,
        output_artifacts_dir,
    )

    # Run inject-files via Image Customizer to inject the signed UKI back into the image
    log.info(
        f"Running imagecustomizer inject-files using YAML: {inject_files_yaml_path}"
    )
    log.debug(
        f"Contents of output artifacts directory: {output_artifacts_dir}:\n"
        + "\n".join([str(p) for p in output_artifacts_dir.rglob("*") if p.is_file()])
    )
    customize.inject_files(
        container_image,
        inject_files_yaml_path,
        unsigned_output_file,
        image.output_format.ic_name(),
        output_file,
        dry_run,
    )


def setup_temp_yaml_and_dir(
    stack: ExitStack,
    image: ImageConfig,
) -> Tuple[Path, Path]:
    """
    Sets up a temporary YAML file and output artifacts directory for building a signed image.
    Returns the path to the temporary YAML file and the output artifacts directory.
    """

    # Figure out the directory of the main YAML file
    yaml_dir = image.full_yaml_path().parent.absolute()

    # Create a temp dir inside yaml_dir to store the unsigned image and output artifacts
    output_artifacts_dir = stack.enter_context(
        temp_dir(prefix=f".{image.id}-", dir=yaml_dir, sudo=True)
    )

    # Now figure out the relative path from yaml_dir to output_artifacts_dir
    tmp_rel_path = output_artifacts_dir.absolute().relative_to(yaml_dir)

    # Update the in-memory config, this is safe because every thread has its own copy of the YAML.
    # We use the relative path because the path should be relative to the YAML location.
    image.base_ic_config["output"]["artifacts"]["path"] = f"./{tmp_rel_path}"

    # Create a thread-specific copy of YAML in the same dir as main YAML
    working_yaml_path = yaml_dir / f".config_{image.id}.yaml"

    with open(working_yaml_path, "w") as f:
        yaml.safe_dump(image.base_ic_config, f)

    # Ensure the temp YAML file is deleted at the end
    stack.enter_context(temp_file(working_yaml_path))

    return working_yaml_path, output_artifacts_dir
