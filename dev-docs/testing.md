# Testing hierarchy

Developers are expected to accompany any features with unit tests, functional
tests for white box testing, and end to end tests for black box testing. See
more details in the following sections.

- [Testing hierarchy](#testing-hierarchy)
  - [Unit Tests](#unit-tests)
  - [Functional Tests](#functional-tests)
    - [Functional Test Structure](#functional-test-structure)
    - [Functional Test Authoring in Rust](#functional-test-authoring-in-rust)
    - [Functional Test Environment](#functional-test-environment)
    - [Functional Test Building and Execution](#functional-test-building-and-execution)
    - [Functional Test Code Coverage](#functional-test-code-coverage)
    - [Additional Notes](#additional-notes)
    - [Selective Test Execution](#selective-test-execution)
  - [E2E Tests](#e2e-tests)


## Unit Tests

Unit tests are meant to test the functionality of a single function in isolation
from everything else. Each module should have a corresponding unit test module
called `tests` annotated with `#[cfg(test)]`. Each test function should be named
`test_*` to indicate which function it is testing and annotated with `#[test]`.

Unit tests can be invoked by `make test` or if code coverage is desired, `make
ut-coverage`.

Unit tests should:

- Not be disruptive to the execution environment, so they can run on development
  machines.
- Execute quickly.
- Be deterministic.
- Be independent of each other.
- Not leave any state behind them.
- Not depend on any external resources, that might not be available on the
  development machine.
- Take advantage of mocking of external resources if possible, to allow testing
as much of the code on the development machine as possible.
- Run in parallel and in a random order.
- Should be the first line of defense for against any regressions.

## Functional Tests

Functional tests are meant to test the functionality of a module or a set of
functions in a real environment. Trident supports two types of functional tests:
manually authored custom tests and test generated from Rust code. Each Rust
module should have a corresponding functional test module called
`functional_test` annotated with:

```rust
#[cfg(feature = "functional-test")]
#[cfg_attr(not(test), allow(unused_imports, dead_code))]
```

Naming of test function is up to the developer, but should be indicative of what
is being tested. Each test function is annotated with `#[functional_test()]`
attribute.

Functional tests can be invoked by `make functional-test` and this will
automatically gather code coverage data as well. This `Makefile` target will
automatically deploy a virtual machine and execute the tests inside it. If a
failure is encountered that can be remedied by fixing either the test code or
feature code the test code calls into, you can run `make patch-functional-test`
to update the test binaries and re-run the tests. More details below.

Functional tests should:

- Test the functionality of a module that cannot be easily unit tested in
  isolation.
- Assume they will not run in parallel to other functions.
- Allow rerunning on the same environment.
- Run as fast as possible.
- Handle validation of external events to the execution environment.
- Aim to target 100% code coverage of the module they are testing (along with
  with the unit tests).

### Functional Test Structure

Functional tests are structured as follows:

- `/functional_tests`: Contains the functional test code, leveraging `pytest`
  and common SSH interface from `k8s-tests` repo. `pytest` creates the test VM
  using is Fixtures concept and while currently only a single VM is created to
  run all the tests, this could be easily extended to support seperate VMs for
  different tests. Most of the time, no changes will be required to this layer
  while developing functional tests.
- `/functional_tests/trident-setup.yaml`: Contains the initial host
  configuration for the VM that will be used to execute the functional tests.
- `/functional_tests/custom/../*.py`: Manually authored Pytest modules for more
  advanced functional tests that can interact with the execution environment,
  such as rebooting the VM or unplugging a disk.
- `/functional_tests/generated/../.py`: Autogenerated wrappers of per module
  `functional_tests` submodules. Contains the actual test implementation written
  in `rust`, leveraging other code already present in Trident. The benefit of
  this approach is that we can leverage common logic and test code is authored
  side by side with the feature code in a consistent manner. This also allows us
  to easily shift logic between unit and functional tests. The autogenerated
  files are not checked in, but instead automatically produced during `make
  *functional-test` Makefile targets.

### Functional Test Authoring in Rust

In order to support autogeneration of the Pytest wrappers, the functional tests
in Rust need to be annotated with `#[functional_test]` attribute (instead of the
regular `#[test]`). The attribute accepts a comma-separated list of key-value
pairs, where the supported keys are: `negative` and `feature`.

The `negative` key is used to mark the test as negative, meaning it tests for a
failure case. The expected associated value type is `boolean`. The `negative`
key is optional, and if not provided, the test will be considered as positive
(aka `negative: false`).

The `feature` key is used to mark the test as belonging to a specific feature.
The expected associated  value type is `string` and supported values are:
`raid`, `verity`, `encryption`, `abupdate`, `core`, `helpers`. The `feature` key
is optional, and if not provided, the test will be considered as belonging to
the `core` feature.

### Functional Test Environment

The functional test environment is a virtual machine that is deployed by the
`virt-deploy` module. At the moment, only a single VM is created, however the
`pytest` Fixture logic is flexible enough to support multiple VMs when needed.

The VM is created using `virt-deploy` and the initial OS provisioning is done
using `netlaunch` and `Trident`. `Trident` will use the checked in
`functional_tests/trident-setup.yaml` `HostConfiguration` for the initial host
deployment. The tests are started on the deployed OS through SSH connection.

In the functional test environment, tests are run on top of block device
/dev/sda. As a result, any changes made by the testing logic should **not**
modify this block device. E.g., this block device should not be reformatted to
a clean filesystem, be mounted/unmounted, etc. On the other hand, **/dev/sdb**
is available for any modifications that are needed for functional testing
purposes.

### Functional Test Building and Execution

There are three ways to build and execute functional tests using `Makefile`
targets:

- `make build-functional-test`: This will just build the tests locally and not
  perform any execution. This is useful to ensure the tests are building. The
  output of this step are set of test binaries, one per crate, which is what
  `cargo test` would normally produce and invoke.

- `make functional-test`: This will build the tests locally with code coverage
  profile (using internal `build-functional-test-cc` target), a new
  `virt-deploy` VM will be created and deployed using `netlaunch`. Afterwards,
  tests will be uploaded into the VM, executed and code coverage will be
  downloaded for later viewing. To note, this will also execute all UTs. If you
  want to iterate on the tests without recreating the VM, but do want to
  redeploy the OS, you can: `make functional-test
  FUNCTIONAL_TEST_EXTRA_PARAMS="--reuse-environment --redeploy"`.

- `make patch-functional-test`: This will build the tests locally with code
  coverage profile (using internal `build-functional-test-cc` target), upload
  the tests into the existing `virt-deploy` VM, execute the tests and download
  code coverage for later viewing. This is useful when you want to iterate on
  the tests and don't want to wait for the VM to be deployed again. It is
  important to note that only tests that have changed will be re-uploaded. This
  is determined based on `cargo build` output. To note, this will also execute
  all UTs.

To execute the functional tests, ensure that `k8s-tests` and `argus-toolkit` of
recent version are checked out side by side with the `trident` repo.
Additionally, the following dependencies are required for the Ubuntu based
pipelines, so you might need to install them on your development machine as well
(note that this set is different per Ubuntu version and is provided just as an
illustration of what works for [pipelines](.pipelines/netlaunch-testing.yml), so
if you are on 22.04 or newer, you might not need to for example reinstall
`python3-openssl`):

```bash
sudo apt install -y protobuf-compiler clang-7 bc
sudo apt remove python3-openssl
pip install pytest assertpy paramiko pyopenssl
ssh-keygen -t rsa -b 2048 -f ~/.ssh/id_rsa -q -N ""
```

Paramiko 2.11.0 and 3.x are known to work, 2.6.0 is known to misbehave.

Finally, ensure that you have locally built or populated the provisioning ISO
template and runtime images. You can populate them from the latest pipeline runs
from the `argus-toolkit` repo as follows:

```bash
az login
make download-provision-template-iso
make download-runtime-partition-images
```

If you hit errors and there is no obvious test case failure, it is possible the
error happened during test setup. Unfortunately, the actionable test setup error
log is not at the end, but higher up in the log, much closer to the beginning.
Scroll up until you see a failure by virt-deploy, netlaunch or trident.

### Functional Test Code Coverage

All functional tests are built with code coverage profile. This means that every
execution will output the profiling data (`*.profraw`), that are needed to
generate the code coverage report. Once the test execution completes, the code
coverage files are downloaded back into the development machine so they can be
aggregated with the locally produced coverage results.

### Additional Notes

`functional-test` target depends on `k8s-tests` and `argus-toolkit` repos to be
checked out side by side with the `trident` repo. This is because `k8s-tests`
repo contains the common logic to execute test logic over SSH connection and
`argus-toolkit` repo contains the `netlaunch` and `virt-deploy` binaries, along
with logic to generate the OS deployment ISO.

Both `functional-test` and `patch-functional-test` targets leverage `pytest`. To
get more detailed logs or do any changes to the `pytest` logic, you can modify
the command line of the `Makefile` targets (e.g. using `-k`  to select a
specific test case to execute), or you can update `functional_tests/pytest.ini`.

Both `functional-test` and `patch-functional-test` targets leverage
`functional_tests/conftest.py` to setup the initial VM, upload the tests and
download the code coverage. Since the setup VM can be leveraged across multiple
runs of `patch-functional-test`, the VM metadata is stored in a test directory
passed from the `Makefile`: `/tmp/trident-test`. You can inspect the command
line options of `conftest.py` to see what is configurable.

The functional test binaries are produced in a fashion that `cargo test` would
use. That means we can leverage all the feature of `cargo test``, such as
randomizing test order or running tests in parallel without additional custom
code.

### Selective Test Execution

The functional test `make` targets support the variable `FILTER`. This is meant to 
be used to filter the tests that are executed. For example, if you want to execute
only the tests from a certain rust crate, you can do:

```bash
make functional-test FILTER=ft.json::<crate>
```

You can narrow down the filter by adding the modules, up to each individual test.

```bash
make functional-test FILTER=ft.json::<crate>::<module1>::<module2>
```

```bash
make functional-test FILTER=ft.json::<crate>::<module>::<test>
```

*NOTE: `ft.json` is the name of the generated JSON file that contains the test
inventory. It is generated during the `make build-functional-test` step. Pytest
node IDs incorporate the file where the test got collected from, so all
rust-based tests will have the `ft.json` prefix.*

You can also do the traditional pytest filtering on native Python tests by using
the python module path:

```bash
# Example to only run tests in the custom/test_trident_e2e.py file
make functional-test FILTER=custom/test_trident_e2e.py
```

## E2E Tests

End to end tests are meant to test the end to end functionality of Trident in a
real environment. E2E tests are using only public Trident interfaces, by
providing `HostConfiguration` and comparing the status of the host to
`HostStatus`. E2E tests are defined under `/e2e_tests` and are currently only
invoked through the e2e validation pipelines. Each Trident feature should be
accompanied by one or more E2E tests.

End to end tests should:

- Leverage only the user facing interfaces of Trident.
- Assume they will not run in parallel to other functions.
- Handle validation of external events to the execution environment.
